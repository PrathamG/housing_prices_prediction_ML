{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nX_full = pd.read_csv('../input/home-data-for-ml-course/train.csv', index_col = 'Id')\nX_full_test = pd.read_csv('../input/home-data-for-ml-course/test.csv', index_col = 'Id')\n\ny = X_full['SalePrice'].copy()\nX = X_full.drop(['SalePrice'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OrdinalEncoder\n\nX_train = X.copy()\ny_train = y.copy()\nX_test = X_full_test.copy()\n\n#col = 79\n#obj_col = 43\n#num_col = 36\n#row = 1460\n\nnum_cols = [col for col in X_train.columns if X_train[col].dtype in ['int64', 'float64']]\nobj_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n\nmissing_num_cols = [col for col in num_cols if X_train[col].isnull().any()]\n\nmissing_obj_cols = [col for col in obj_cols if X_train[col].isnull().any()]\nimpute_const_cols = list(set(missing_obj_cols) - set(['MasVnrType', 'Electrical']))\nimpute_freq_cols = list(set(obj_cols) - set(impute_const_cols))\n\nord_enc_cols = ['ExterQual', 'ExterCond', 'BsmtQual','BsmtCond',\n            'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', \n            'GarageCond', 'PoolQC']\n\nnon_ord_enc_cols = list(set(obj_cols) - set(ord_enc_cols))\nlabel_enc_cols = [col for col in non_ord_enc_cols if X_train[col].nunique()>=8]\noh_enc_cols = list(set(non_ord_enc_cols) - set(label_enc_cols))\n\n#impute categorical variables in X_train\nX_train[impute_const_cols] = X_train[impute_const_cols].fillna(value = 'Absent')\nX_train[impute_freq_cols] = X_train[impute_freq_cols].apply(lambda x:x.fillna(x.value_counts().index[0]))\n\n#impute categorical variables in X_test\nX_test[impute_const_cols] = X_test[impute_const_cols].fillna(value = 'Absent')\nX_test[impute_freq_cols] = X_test[impute_freq_cols].apply(lambda x:x.fillna(x.value_counts().index[0]))\n\n\ncat = ['Absent','Po', 'Fa', 'TA', 'Gd', 'Ex']\n\n#ordinalEncode respective categorical variables in X_train\nord_encoder = OrdinalEncoder(categories = [cat for col in range(0, len(ord_enc_cols))])\nX_encoded = pd.DataFrame(ord_encoder.fit_transform(X_train[ord_enc_cols]))\nX_encoded.index = X_train.index\nX_train[ord_enc_cols] = X_encoded\n\n#ordinalEncode respective categorical variables in X_test\nX_encoded_test = pd.DataFrame(ord_encoder.transform(X_test[ord_enc_cols]))\nX_encoded_test.index = X_test.index\nX_test[ord_enc_cols] = X_encoded_test\n\nlabel_enc_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing._encoders import _BaseEncoder\nclass new_OrdinalEncoder(_BaseEncoder):\n    def __init__(self,cat_index='all'):\n        self.dicts={}\n        # cate_index is the categorical feature index list\n        self.cat_index=cat_index\n     \n    def fit(self,df,*y):\n        if self.cat_index=='all':\n            self.cat_index=list(range(df.shape[1]))\n        for feat in self.cat_index:\n            dic=np.unique(df.iloc[:,feat])\n            dic=dict([(i,index) for index, i in enumerate(dic)])\n            self.dicts[feat]=dic\n             \n    def fit_transform(self,df,*y):\n        if self.cat_index=='all':\n            self.cat_index=list(range(df.shape[1]))\n        df_output=df.copy()\n        for feat in self.cat_index:\n            dic=np.unique(df.iloc[:,feat])\n            dic=dict([(i,index) for index, i in enumerate(dic)])\n            self.dicts[feat]=dic\n            df_output.iloc[:,feat]=df.iloc[:,feat].apply(lambda x: dic[x])\n        return df_output\n         \n    def transform(self,df):\n        df_output=df.copy()\n        for feat in self.cat_index:\n            dic=self.dicts[feat]\n            df_output.iloc[:,feat]=df.iloc[:,feat].apply(self.unknown_value,args=(dic,))\n        return df_output\n     \n    def unknown_value(self,value,dic): # It will set up a new interger for unknown values!\n        try:\n            return dic[value]\n        except:\n            return len(dic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\n\nmodel = XGBRegressor(n_estimators = 700, learning_rate = 0.04, random_state = 0)\n\noh_encoder = OneHotEncoder(handle_unknown = 'ignore')\nle_encoder = new_OrdinalEncoder()\n\npreprocessor = ColumnTransformer([\n    ('num_imputer', SimpleImputer(strategy = 'median'), num_cols),\n    ('le_enc', le_encoder, label_enc_cols),\n    ('oh_enc', oh_encoder, oh_enc_cols)\n], remainder = 'passthrough')\n\nmy_pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('model', model)\n])\n\nmy_pipeline.fit(X_train, y_train)\n#score = -1 * (cross_val_score(my_pipeline, X_train, y_train, cv = 4, scoring='neg_mean_absolute_error'))\n#score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef get_score(n):\n    model = RandomForestRegressor(n_estimators = n, random_state=0)\n    my_pipeline = Pipeline([\n        ('preprocessor', preprocessor),\n        ('model', model)\n    ])\n    score = -1 * (cross_val_score(my_pipeline, X_train, y_train, cv = 4, scoring='neg_mean_absolute_error'))\n    return score.mean()\n\nestimators_list = []\nfor n in estimators_list:\n    print(n)\n    print(get_score(n))\n\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {\n    'model__n_estimators': [500, 600, 700, 800],\n    'model__learning_rate': [0.02, 0.04, 0.05, 0.08]\n}\ngrid_search = GridSearchCV(estimator = my_pipeline, cv = 4, param_grid = param_grid, scoring='neg_mean_absolute_error')\ngrid_search.fit(X_train, y_train)\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = my_pipeline.predict(X_test)\noutput = pd.DataFrame({'Id': X_test.index,\n                       'SalePrice': test_predictions})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}